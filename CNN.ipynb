{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff704f6e",
   "metadata": {},
   "source": [
    "## Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe3f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor  # turns image data into tensors\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load MNIST using torchvision\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),  # convert to tensor\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),  # standardizes pixel values\n",
    "    ]\n",
    ")\n",
    "# Create datasets for training & validation, download if necessary\n",
    "train_dataset = datasets.MNIST(\"./data\", train=True, transform=transform, download=True)\n",
    "test_dataset = datasets.MNIST(\"./data\", train=False, transform=transform, download=True)\n",
    "\n",
    "# Create data loaders for our datasets; shuffle for training, not for validation\n",
    "loaders = {\n",
    "    \"train\": DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=0),\n",
    "    \"test\": DataLoader(train_dataset, batch_size=100, shuffle=True, num_workers=0),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f78993",
   "metadata": {},
   "source": [
    "### Visual of Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88254293",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as py\n",
    "\n",
    "x_train = train_dataset.data.numpy()\n",
    "y_train = train_dataset.targets.numpy()\n",
    "\n",
    "x_test = test_dataset.data.numpy()\n",
    "y_test = test_dataset.targets.numpy()\n",
    "\n",
    "images_2_show = []\n",
    "titles_2_show = []\n",
    "\n",
    "\n",
    "def show_images(images, title_texts):\n",
    "    cols = 5\n",
    "    rows = int(len(images) / cols) + 1\n",
    "    plt.figure(figsize=(30, 20))\n",
    "    index = 1\n",
    "    for x in zip(images, title_texts):\n",
    "        image = x[0]\n",
    "        title_text = x[1]\n",
    "        plt.subplot(rows, cols, index)\n",
    "        plt.imshow(image, cmap=plt.cm.gray)\n",
    "        if title_text != \"\":\n",
    "            plt.title(title_text, fontsize=15)\n",
    "        index += 1\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    r = random.randint(0, 59999)\n",
    "    images_2_show.append(x_train[r])\n",
    "    titles_2_show.append(f\"training image [{r}] = {y_train[r]}\")\n",
    "\n",
    "for i in range(5):\n",
    "    r = random.randint(0, 9999)\n",
    "    images_2_show.append(x_test[r])\n",
    "    titles_2_show.append(f\"test image [{r}] = {y_test[r]}\")\n",
    "\n",
    "show_images(images_2_show, titles_2_show)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b575ffc",
   "metadata": {},
   "source": [
    "### Checking logistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c8db09",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacf0291",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff540c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3139c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.data.shape  # one channel, 28x28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3676130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f77636",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.targets  # digits from 0-9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2dca616",
   "metadata": {},
   "source": [
    "# Defining Model's Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f322249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim  # optimization module\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        # ^regularization layer,\n",
    "        # ignores nodes randomly during TRAINING,\n",
    "        # irrelevant in TESTING,\n",
    "        # doesn't change shape of data\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2(x), 2))\n",
    "        # x.view(-1, 320)  # 20*4*4 = 320; flattening 320 nodes\n",
    "        x = x.view(x.size(0), -1)  # flattening 320 nodes\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # return F.softmax(x, dim=1)\n",
    "        return x\n",
    "\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5813789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import datetime\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\n",
    "    \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    ")  # cpu is slower than GPU\n",
    "\n",
    "model = Net().to(\n",
    "    device\n",
    ")  # must move model, tensors, etc. to GPU if using cuda device (i have no idea what cuda device is)\n",
    "\n",
    "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "writer = SummaryWriter(\"runs/cnn_model_{}\".format(timestamp))\n",
    "\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()  # model put into training mode (important for dropout and batchnormalization)\n",
    "    for batch_idx, (data, target) in enumerate(loaders[\"train\"]):\n",
    "        data, target = data.to(device), target.to(device)  # move to GPU if using cuda\n",
    "        optimizer.zero_grad()  # zero the parameter gradients\n",
    "        output = model(data)  # forward pass\n",
    "        loss = loss_fn(output, target)  # compute loss\n",
    "        loss.backward()  # backward pass\n",
    "        optimizer.step()  # optimize weights\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(\n",
    "                f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)}\"\n",
    "                f\" ({100.0 * batch_idx / len(loaders['train']):.0f}%)]\\tLoss: {loss.item():.6f}\",\n",
    "            )\n",
    "            model_path = \"model_{}_{}\".format(timestamp, epoch)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "    writer.add_scalar(\n",
    "        \"Loss/train\", loss.item(), epoch * len(loaders[\"train\"]) + batch_idx\n",
    "    )\n",
    "    writer.flush()\n",
    "\n",
    "\n",
    "def test():\n",
    "    model.eval()  # put model into evaluation mode\n",
    "\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():  # no need to track gradients during evaluation\n",
    "        for data, target in loaders[\"test\"]:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_fn(output, target).item()  # sum up batch loss\n",
    "            pred = output.argmax(\n",
    "                dim=1, keepdim=True\n",
    "            )  # get the index of the max log-probability\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(loaders[\"test\"].dataset)\n",
    "\n",
    "    print(\n",
    "        f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loaders['test'].dataset)}\"\n",
    "        f\" ({100.0 * correct / len(loaders['test'].dataset):.0f}%)\\n\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dd6ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 11):  # 10 epochs\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff67cade",
   "metadata": {},
   "source": [
    "## Accuracy Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343034fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.14/site-packages (1.7.2)\n",
      "Requirement already satisfied: numpy>=1.22.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn) (2.3.4)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.14/site-packages (from scikit-learn) (3.6.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    ")\n",
    "\n",
    "\n",
    "def evaluate_cnn(model, dataloader, device=\"cpu\", average=\"macro\"):\n",
    "    \"\"\"\n",
    "    Evaluate a PyTorch CNN on a multi-class dataset using scikit-learn metrics.\n",
    "\n",
    "    Parameters:\n",
    "    - model: trained PyTorch model\n",
    "    - dataloader: DataLoader for test/validation data\n",
    "    - device: 'cpu' or 'cuda'\n",
    "    - average: averaging method for multi-class metrics ('macro', 'micro', 'weighted')\n",
    "\n",
    "    Returns:\n",
    "    - Dictionary with accuracy, precision, recall, f1, and classification report\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in dataloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            preds = outputs.argmax(dim=1)  # get predicted class\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(target.cpu().numpy())\n",
    "\n",
    "    all_preds = np.array(all_preds)\n",
    "    all_labels = np.array(all_labels)\n",
    "\n",
    "    metrics = {\n",
    "        \"accuracy\": accuracy_score(all_labels, all_preds),\n",
    "        \"precision\": precision_score(all_labels, all_preds, average=average),\n",
    "        \"recall\": recall_score(all_labels, all_preds, average=average),\n",
    "        \"f1\": f1_score(all_labels, all_preds, average=average),\n",
    "        \"report\": classification_report(all_labels, all_preds),\n",
    "    }\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b626b8b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92795\n",
      "Precision: 0.9275678224015922\n",
      "Recall: 0.9272104475312541\n",
      "F1 Score: 0.9272339302245027\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.96      0.96      5923\n",
      "           1       0.96      0.97      0.97      6742\n",
      "           2       0.94      0.91      0.93      5958\n",
      "           3       0.92      0.90      0.91      6131\n",
      "           4       0.93      0.91      0.92      5842\n",
      "           5       0.90      0.92      0.91      5421\n",
      "           6       0.95      0.97      0.96      5918\n",
      "           7       0.92      0.95      0.93      6265\n",
      "           8       0.93      0.88      0.90      5851\n",
      "           9       0.87      0.90      0.89      5949\n",
      "\n",
      "    accuracy                           0.93     60000\n",
      "   macro avg       0.93      0.93      0.93     60000\n",
      "weighted avg       0.93      0.93      0.93     60000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = evaluate_cnn(model, loaders[\"test\"], device=device, average=\"macro\")\n",
    "\n",
    "print(\"Accuracy:\", metrics[\"accuracy\"])\n",
    "print(\"Precision:\", metrics[\"precision\"])\n",
    "print(\"Recall:\", metrics[\"recall\"])\n",
    "print(\"F1 Score:\", metrics[\"f1\"])\n",
    "print(metrics[\"report\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11375a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360de272",
   "metadata": {},
   "source": [
    "## Visualize predictions \n",
    "- by changing number in test_dataset[num]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4faecfd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "model.eval()\n",
    "\n",
    "data, target = test_dataset[4]\n",
    "\n",
    "data = data.unsqueeze(0).to(device)\n",
    "\n",
    "output = model(data)\n",
    "\n",
    "prediction = output.argmax(dim=1, keepdim=True).item()\n",
    "\n",
    "print(f\"Prediction: {prediction}\")\n",
    "\n",
    "image = data.squeeze(0).squeeze(0).cpu().numpy()\n",
    "\n",
    "plt.imshow(image, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0412f964",
   "metadata": {},
   "source": [
    "## Saving the model to path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc312a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"numreader.pth\")\n",
    "saved_model = Net()\n",
    "saved_model.load_state_dict(torch.load(\"numreader.pth\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.14.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
