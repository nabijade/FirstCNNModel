{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d7ff4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e8fd18",
   "metadata": {},
   "source": [
    "## Preprocessing and Normalizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "376ee585",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 28, 28\n",
    "\n",
    "# Reshape the data into a 4D Array\n",
    "x_train = x_train.reshape(x_train.shape[0], rows, cols, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], rows, cols, 1)\n",
    "\n",
    "input_shape = (rows, cols, 1)\n",
    "\n",
    "# Set type as float32 and normalize the values to [0,1]\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n",
    "\n",
    "# Transform labels to one hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe2268a0",
   "metadata": {},
   "source": [
    "## Defining LeNet-5 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "415fb382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lenet(input_shape):\n",
    "    # Define Sequential Model\n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # C1 Convolution Layer\n",
    "    model.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=6,\n",
    "            strides=(1, 1),\n",
    "            kernel_size=(5, 5),\n",
    "            activation=\"tanh\",\n",
    "            input_shape=input_shape,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # S2 SubSampling Layer\n",
    "    model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # C3 Convolution Layer\n",
    "    model.add(\n",
    "        tf.keras.layers.Conv2D(\n",
    "            filters=6, strides=(1, 1), kernel_size=(5, 5), activation=\"tanh\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # S4 SubSampling Layer\n",
    "    model.add(tf.keras.layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "\n",
    "    # C5 Fully Connected Layer\n",
    "    model.add(tf.keras.layers.Dense(units=120, activation=\"tanh\"))\n",
    "\n",
    "    # Flatten the output so that we can connect it with the fully connected layers by converting it into a 1D Array\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "\n",
    "    # FC6 Fully Connected Layers\n",
    "    model.add(tf.keras.layers.Dense(units=84, activation=\"tanh\"))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(tf.keras.layers.Dense(units=10, activation=\"softmax\"))\n",
    "\n",
    "    # Compile the Model\n",
    "    model.compile(\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.0, decay=0.0),\n",
    "        metrics=[\"accuracy\"],\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e048c5ea",
   "metadata": {},
   "source": [
    "## Evaluate Model and Visualize Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acee502a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nabijade/Desktop/Repositories/FirstCNNModel/.venv11/lib/python3.11/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/Users/nabijade/Desktop/Repositories/FirstCNNModel/.venv11/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.4321\n",
      "Epoch 2/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9451 - loss: 0.1858\n",
      "Epoch 3/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9600 - loss: 0.1351\n",
      "Epoch 4/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9672 - loss: 0.1089\n",
      "Epoch 5/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9720 - loss: 0.0921\n",
      "Epoch 6/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9756 - loss: 0.0811\n",
      "Epoch 7/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9785 - loss: 0.0716\n",
      "Epoch 8/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9808 - loss: 0.0650\n",
      "Epoch 9/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9825 - loss: 0.0596\n",
      "Epoch 10/10\n",
      "\u001b[1m469/469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9837 - loss: 0.0548\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9808 - loss: 0.0586\n",
      "Accuracy :  0.9807999730110168\n",
      "Training Data (60000, 28, 28) (60000, 10)\n",
      "Test Data (10000, 28, 28) (10000, 10)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "6\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenet = build_lenet(input_shape)\n",
    "\n",
    "# We will be allowing 10 itterations to happen\n",
    "epochs = 10\n",
    "history = lenet.fit(\n",
    "    x_train, y_train, epochs=epochs, batch_size=128, verbose=1\n",
    ")  # verbose means progress bar\n",
    "\n",
    "# Check Accuracy of the Model\n",
    "loss, acc = lenet.evaluate(x_test, y_test)\n",
    "print(\"Accuracy : \", acc)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28)\n",
    "print(\"Training Data\", x_train.shape, y_train.shape)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28)\n",
    "print(\"Test Data\", x_test.shape, y_test.shape)\n",
    "\n",
    "# Plot the Image\n",
    "image_index = 8888\n",
    "plt.imshow(x_test[image_index].reshape(28, 28), cmap=\"Greys\")\n",
    "\n",
    "# Make Prediction\n",
    "pred = lenet.predict(x_test[image_index].reshape(1, rows, cols, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8cde0ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0900 - loss: 7.3129  \n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.0500 - loss: 3.7543\n",
      "Random Data Accuracy: 0.05000000074505806\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step\n",
      "Predicted digit (random): 7\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# Suppose your model expects 28x28 grayscale images\n",
    "rows, cols = 28, 28\n",
    "num_classes = 10  # digits 0-9\n",
    "\n",
    "# Create a random batch of 100 \"images\"\n",
    "x_random = np.random.rand(100, rows, cols, 1).astype(np.float32)\n",
    "\n",
    "# Create random labels (one-hot encoded)\n",
    "y_random = tf.keras.utils.to_categorical(\n",
    "    np.random.randint(0, num_classes, 100), num_classes\n",
    ")\n",
    "\n",
    "# Assume you have a CNN model called 'lenet'\n",
    "# Compile the model if you haven't already\n",
    "lenet.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.1),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Train the model on random data (just to see it run)\n",
    "history = lenet.fit(x_random, y_random, epochs=1, batch_size=16)\n",
    "\n",
    "# Evaluate on another batch of random data\n",
    "x_test_random = np.random.rand(20, rows, cols, 1).astype(np.float32)\n",
    "y_test_random = tf.keras.utils.to_categorical(\n",
    "    np.random.randint(0, num_classes, 20), num_classes\n",
    ")\n",
    "\n",
    "loss, acc = lenet.evaluate(x_test_random, y_test_random)\n",
    "print(\"Random Data Accuracy:\", acc)\n",
    "\n",
    "# Make a prediction\n",
    "sample_image = np.random.rand(1, rows, cols, 1).astype(np.float32)\n",
    "pred = lenet.predict(sample_image)\n",
    "print(\"Predicted digit (random):\", pred.argmax())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv11 (3.11.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
